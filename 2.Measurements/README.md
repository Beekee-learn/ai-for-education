Measurements
---

To assess the operational performance of the Raspberry Pi during LLM inference, we collected various metrics while conducting inference tests with 1, 2, 4, or 8 users simultaneously and for each case using 1, 2, 3, or 4 threads. Here are the results of these measurements and the accompanying analysis.
- [Temperature](/2.Measurements/temperature.md)
- [CPU](/2.Measurements/cpu.md)
- [Memory](/2.Measurements/memory.md)
- [Energy and Power](/2.Measurements/energyPower.md)
- [Inference time](/2.Measurements/inferenceTime.md)
